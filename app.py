import os
import time
import json
import re
import google.generativeai as genai
import streamlit as st
from prompt import PROMPT_WORKAW
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from google.api_core.exceptions import ResourceExhausted
from typing import Dict, List, Any

# Import enhanced document reader
try:
    from document_reader import EnhancedDocumentReader, get_kmutnb_summary, search_in_document
    ENHANCED_READER_AVAILABLE = True
except ImportError:
    ENHANCED_READER_AVAILABLE = False
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
    def get_kmutnb_summary(file_path: str, use_ocr: bool = False, expert_role: str = "") -> str:
        try:
            if file_path.lower().endswith('.txt'):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            elif file_path.lower().endswith('.pdf'):
                try:
                    import fitz
                    doc = fitz.open(file_path)
                    content = ""
                    for page in doc:
                        content += page.get_text()
                    doc.close()
                except ImportError:
                    return "Error: PyMuPDF not installed. Please install: pip install PyMuPDF"
            else:
                return "Error: Unsupported file type. Please use .txt or .pdf"
            
            if len(content) > 15000:
                content = content[:15000] + "\n\n[‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î token]"
            
            return content
        except Exception as e:
            return f"Error reading file: {str(e)}"

# Configure API
genai.configure(api_key="AIzaSyA4YjD2FBii2N7HtWq4LWtIPpZLthonp6c")

# Enhanced generation config
generation_config = {
    "temperature": 0.1,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE
}

# Enhanced prompt for direct responses
ENHANCED_PROMPT_WORKAW = """
‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô AI Assistant ‡∏Ç‡∏≠‡∏á‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏û‡∏£‡∏∞‡∏à‡∏≠‡∏°‡πÄ‡∏Å‡∏•‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ (KMUTNB) 

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
1. ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢
2. ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
3. ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
4. ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
5. ‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏ï‡∏£‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô
6. ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ö‡∏≠‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô

‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: "‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î 15 ‡∏™‡∏≤‡∏Ç‡∏≤ ‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏• ‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡πÑ‡∏ü‡∏ü‡πâ‡∏≤..."
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
"""

model = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    safety_settings=SAFETY_SETTINGS,
    generation_config=generation_config,
    system_instruction=ENHANCED_PROMPT_WORKAW,
)

# Enhanced Rate limiting with better tracking
class EnhancedRateLimiter:
    def __init__(self):
        if 'api_calls' not in st.session_state:
            st.session_state.api_calls = []
        if 'api_errors' not in st.session_state:
            st.session_state.api_errors = []
        if 'total_tokens_used' not in st.session_state:
            st.session_state.total_tokens_used = 0
    
    def can_make_request(self):
        current_time = time.time()
        st.session_state.api_calls = [
            call_time for call_time in st.session_state.api_calls 
            if current_time - call_time < 60
        ]
        return len(st.session_state.api_calls) < 10
    
    def add_request(self, tokens_used: int = 0):
        st.session_state.api_calls.append(time.time())
        st.session_state.total_tokens_used += tokens_used
    
    def add_error(self, error_msg: str):
        st.session_state.api_errors.append({
            'time': time.time(),
            'error': error_msg
        })
        if len(st.session_state.api_errors) > 10:
            st.session_state.api_errors = st.session_state.api_errors[-10:]
    
    def time_until_next_request(self):
        if not st.session_state.api_calls:
            return 0
        oldest_call = min(st.session_state.api_calls)
        return max(0, 60 - (time.time() - oldest_call))

    def get_recent_errors(self):
        current_time = time.time()
        return [
            error for error in st.session_state.api_errors
            if current_time - error['time'] < 300
        ]

rate_limiter = EnhancedRateLimiter()

# Document management with OCR and expert role support
class DocumentManager:
    def __init__(self):
        if 'document_content' not in st.session_state:
            st.session_state.document_content = None
        if 'document_metadata' not in st.session_state:
            st.session_state.document_metadata = {}
        if 'document_sections' not in st.session_state:
            st.session_state.document_sections = {}
        if 'document_keywords' not in st.session_state:
            st.session_state.document_keywords = []
        if 'last_file_path' not in st.session_state:
            st.session_state.last_file_path = None
        if 'use_ocr' not in st.session_state:
            st.session_state.use_ocr = False
        if 'expert_role' not in st.session_state:
            st.session_state.expert_role = ""
    
    def load_document(self, file_path: str, use_ocr: bool = False, expert_role: str = "") -> tuple[str, str]:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        needs_reload = (
            st.session_state.last_file_path != file_path or
            st.session_state.use_ocr != use_ocr or
            st.session_state.expert_role != expert_role or
            not st.session_state.document_content
        )
        
        if not needs_reload:
            return st.session_state.document_content, "‚úÖ ‡πÉ‡∏ä‡πâ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß"
        
        if not os.path.exists(file_path):
            search_paths = self._get_search_paths(file_path)
            
            for path in search_paths:
                if os.path.exists(path):
                    file_path = path
                    break
            else:
                return None, f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {file_path}"
        
        try:
            if ENHANCED_READER_AVAILABLE:
                reader = EnhancedDocumentReader(file_path, use_ocr=use_ocr, expert_role=expert_role)
                content = reader.get_comprehensive_summary()
                
                st.session_state.document_metadata = reader.metadata
                st.session_state.document_sections = reader.sections
                st.session_state.document_keywords = list(reader.keywords)
                
                status = f"‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Enhanced Mode)"
                if use_ocr:
                    status += " + OCR"
                if expert_role:
                    status += f" | ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç: {expert_role}"
                status += f" - {len(content):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
                
                if reader.metadata:
                    status += f" | ‡∏´‡∏ô‡πâ‡∏≤: {reader.metadata.get('pages', '‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö')}"
            else:
                content = get_kmutnb_summary(file_path, use_ocr=use_ocr, expert_role=expert_role)
                status = f"‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Basic Mode) - {len(content):,} ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
            
            if content.startswith("Error:"):
                return None, content
            
            st.session_state.document_content = content
            st.session_state.last_file_path = file_path
            st.session_state.use_ocr = use_ocr
            st.session_state.expert_role = expert_role
            
            return content, status
            
        except Exception as e:
            error_msg = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"
            return None, error_msg
    
    def _get_search_paths(self, original_path: str) -> List[str]:
        current_dir = os.path.dirname(__file__) if __file__ else os.getcwd()
        filename = os.path.basename(original_path)
        
        search_paths = [
            original_path,
            os.path.join(current_dir, filename),
            os.path.join(current_dir, "dataset_reseach.pdf"),
            os.path.join(current_dir, "dataset.pdf"),
            os.path.join(current_dir, "data.pdf"),
            os.path.join(current_dir, "kmutnb.pdf"),
            os.path.join(current_dir, "kmutnb_data.pdf"),
            os.path.join(current_dir, "documents", filename),
            os.path.join(current_dir, "data", filename),
        ]
        
        return search_paths
    
    def search_document(self, search_term: str) -> str:
        if not st.session_state.document_content:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        if ENHANCED_READER_AVAILABLE and st.session_state.last_file_path:
            result = search_in_document(
                st.session_state.last_file_path, 
                search_term, 
                use_ocr=st.session_state.use_ocr
            )
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if "‡πÑ‡∏°‡πà‡∏û‡∏ö" in result or "‚ùå" in result:
                return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
            return result
        else:
            content = st.session_state.document_content
            lines = content.split('\n')
            found_lines = []
            
            for i, line in enumerate(lines):
                if search_term.lower() in line.lower():
                    context_start = max(0, i-1)
                    context_end = min(len(lines), i+2)
                    context = lines[context_start:context_end]
                    found_lines.append(f"=== ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà {i+1} ===\n" + '\n'.join(context) + "\n")
            
            if found_lines:
                return f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '{search_term}' ‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ {len(found_lines)} ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á:\n\n" + '\n'.join(found_lines[:5])
            else:
                return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

doc_manager = DocumentManager()

def clear_history():
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏∞"}
    ]
    st.rerun()

def safe_api_call(api_function, max_retries=3):
    for attempt in range(max_retries):
        try:
            if not rate_limiter.can_make_request():
                wait_time = rate_limiter.time_until_next_request()
                if wait_time > 0:
                    st.warning(f"‚è≥ ‡∏£‡∏≠ {wait_time:.0f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å rate limit")
                    time.sleep(wait_time + 1)
            
            result = api_function()
            rate_limiter.add_request(tokens_used=100)
            return result
            
        except ResourceExhausted as e:
            error_msg = f"API quota ‡πÄ‡∏Å‡∏¥‡∏ô (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 1})"
            rate_limiter.add_error(error_msg)
            
            wait_time = 60 * (attempt + 1)
            if attempt < max_retries - 1:
                st.warning(f"‚ö†Ô∏è {error_msg}! ‡∏£‡∏≠ {wait_time} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...")
                time.sleep(wait_time)
            else:
                return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
                
        except Exception as e:
            error_msg = f"API Error: {str(e)}"
            rate_limiter.add_error(error_msg)
            
            if attempt < max_retries - 1:
                st.warning(f"‚ö†Ô∏è {error_msg} (‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt + 2})")
                time.sleep(5 * (attempt + 1))
            else:
                return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    
    return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"

def enhanced_response_generation(prompt: str, document_content: str, expert_role: str = "") -> str:
    question_type = analyze_question_type(prompt)
    enhanced_prompt = enhance_prompt_based_on_type(prompt, question_type, expert_role)
    
    def generate_response():
        history = []
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        instruction = """
‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
- ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢
- ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
- ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢" "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©" "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏ï‡∏≤‡∏°" "‡∏ô‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢"
- ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        """
        
        history.append({
            "role": "user", 
            "parts": [{"text": f"{instruction}\n\n‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:\n{document_content}"}]
        })
        
        recent_messages = st.session_state["messages"][-10:]
        for msg in recent_messages:
            history.append({
                "role": msg["role"], 
                "parts": [{"text": msg["content"]}]
            })
        
        chat_session = model.start_chat(history=history)
        response = chat_session.send_message(enhanced_prompt)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
        cleaned_response = clean_response(response.text)
        return cleaned_response
    
    return safe_api_call(generate_response)

def clean_response(response_text: str) -> str:
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö ‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏≠‡∏≠‡∏Å"""
    
    # ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    unwanted_phrases = [
        "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢", "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©", "‡πÄ‡∏™‡∏µ‡∏¢‡πÉ‡∏à‡∏î‡πâ‡∏ß‡∏¢", "‡∏ô‡πà‡∏≤‡πÄ‡∏™‡∏µ‡∏¢‡∏î‡∏≤‡∏¢",
        "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡¶∞‡∏Å‡πá‡∏ï‡∏≤‡∏°", "‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡∏Å‡πá‡∏î‡∏µ", "‡πÅ‡∏ï‡πà‡∏ó‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ",
        "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞", "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏©‡∏Ñ‡πà‡∏∞"
    ]
    
    # ‡∏•‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢
    sentences = response_text.split('.')
    cleaned_sentences = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if sentence and not any(phrase in sentence for phrase in unwanted_phrases):
            cleaned_sentences.append(sentence)
    
    cleaned_response = '. '.join(cleaned_sentences)
    
    # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå
    if not cleaned_response.strip() or len(cleaned_response.strip()) < 10:
        return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
    
    return cleaned_response.strip()

def analyze_question_type(prompt: str) -> str:
    prompt_lower = prompt.lower()
    
    if any(word in prompt_lower for word in ['‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤', '‡∏´‡∏≤', 'search', 'find']):
        return 'search'
    elif any(word in prompt_lower for word in ['‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö', 'compare', '‡∏ï‡πà‡∏≤‡∏á', '‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô']):
        return 'compare'
    elif any(word in prompt_lower for word in ['‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢', 'explain', '‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£', '‡∏ó‡∏≥‡πÑ‡∏°', '‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£']):
        return 'explain'
    elif any(word in prompt_lower for word in ['‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠', 'list', '‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á', '‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î']):
        return 'list'
    elif any(word in prompt_lower for word in ['‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á', 'example', '‡πÄ‡∏ä‡πà‡∏ô']):
        return 'example'
    else:
        return 'general'

def enhance_prompt_based_on_type(prompt: str, question_type: str, expert_role: str = "") -> str:
    base_enhancement = ""
    if expert_role:
        base_enhancement = f"‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô {expert_role} "
    
    enhancements = {
        'search': f"{base_enhancement}‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î: ",
        'compare': f"{base_enhancement}‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô: ",
        'explain': f"{base_enhancement}‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö: ",
        'list': f"{base_enhancement}‡∏à‡∏±‡∏î‡∏ó‡∏≥‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö: ",
        'example': f"{base_enhancement}‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢: ",
        'general': f"{base_enhancement}‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô: "
    }
    
    return enhancements.get(question_type, base_enhancement + "‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô: ") + prompt

# Page config
st.set_page_config(
    page_title="KMUTNB Chatbot",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Sidebar with enhanced controls
with st.sidebar:
    st.header("Settings")
    
    # OCR Settings
    use_ocr = st.checkbox("OCR PDF", value=False, 
                         help="‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ OCR ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô PDF ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠ scanned document")
    
    # Expert Role Settings
    expert_role = st.text_input("Role", 
                               placeholder="",
                               help="‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô")
    
    # Document Settings
    st.subheader("Document")
    file_path = st.text_input("Path File Document", 
                             value="/Users/zayxaxto/Documents/kmutnb_chatbot/workaw/Last Dataset.pdf",
                             help="‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
    
    if st.button("Reload", use_container_width=True):
        st.session_state.document_content = None
        st.rerun()
    
    if st.button("Clear History", use_container_width=True):
        clear_history()

# Main app
st.title("üí¨ KMUTNB Enhanced Chatbot")
st.write("‡∏£‡∏∞‡∏ö‡∏ö AI ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏ï‡∏£‡∏á‡∏°‡∏≤")

# Initialize messages
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {
            "role": "model",
            "content": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö KMUTNB ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏î‡∏Ñ‡∏∞",
        }
    ]

# Load document with new settings
file_content, load_status = doc_manager.load_document(file_path, use_ocr=use_ocr, expert_role=expert_role)

# Display load status
if file_content is None:
    st.error(f"‚ùå {load_status}")
    st.info("üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡∏±‡∏ö app.py")
    
    with st.expander("üìÅ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå"):
        search_paths = doc_manager._get_search_paths(file_path)
        for path in search_paths:
            status = "‚úÖ" if os.path.exists(path) else "‚ùå"
            st.markdown(f"**{status}** `{path}`")
else:
    st.success(f"‚úÖ {load_status}")

# Display messages
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# Chat input
if prompt := st.chat_input("üí≠ Type your question"):
    if file_content is None:
        st.error("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.stop()
    
    if not rate_limiter.can_make_request():
        wait_time = rate_limiter.time_until_next_request()
        st.error(f"‚è≥ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏≠ {wait_time:.0f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà")
        st.stop()
    
    st.session_state["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)
    
    with st.chat_message("model"):
        with st.spinner("ü§î ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°..."):
            
            if prompt.lower().startswith("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:") or prompt.lower().startswith("search:"):
                search_term = prompt.split(":", 1)[1].strip()
                response_text = doc_manager.search_document(search_term)
            else:
                response_text = enhanced_response_generation(prompt, file_content, expert_role)
            
            st.write(response_text)
            st.session_state["messages"].append({"role": "model", "content": response_text})
